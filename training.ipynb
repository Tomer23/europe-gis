{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "eugis",
   "display_name": "eugis"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "module_path = str(pathlib.Path().absolute()).replace('/notebooks', '')\n",
    "sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.jobs.dataset_creation import ReadRasterFile, StridedArrayGenerator, PreProcessBorderRaster, StoreCompositeDataHDF5, PreProcessPopulationRaster\n",
    "\n",
    "raster_dem_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/dem_aggr_rst.tif'\n",
    "raster_pop_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_rst.tif'\n",
    "raster_nuts_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/nuts_rst.tif'\n",
    "\n",
    "model_name = 'pop_nuts'\n",
    "\n",
    "rasters = {\n",
    "    'pop': {\n",
    "        'type': 'input',\n",
    "        'data': PreProcessPopulationRaster(ReadRasterFile(raster_pop_fn)),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'nuts': {\n",
    "        'type': 'output',\n",
    "        'data': PreProcessBorderRaster(ReadRasterFile(raster_nuts_fn), bad_value=-1),\n",
    "        'bad_value_threshold': -1\n",
    "    }\n",
    "}\n",
    "strided_generator = StridedArrayGenerator(rasters, window_size = 100)\n",
    "step = 0\n",
    "while True:\n",
    "    (train_x, train_y), (test_x, test_y) = next(strided_generator)\n",
    "    if train_x.shape[0] == 0:\n",
    "        break\n",
    "    else:\n",
    "        for i in range(2):\n",
    "            selection_mask = [(x == i)[0] for x in train_y]\n",
    "            StoreCompositeDataHDF5(train_x[selection_mask], train_y[selection_mask], model_name + '_train_' + str(i) + '_' + str(step))\n",
    "            selection_mask = [(x == i)[0] for x in test_y]\n",
    "            StoreCompositeDataHDF5(test_x[selection_mask], test_y[selection_mask], model_name + '_test_' + str(i) + '_' + str(step))\n",
    "        step += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from scripts.jobs.dataset_creation import CreateTFDatasetFromCompositeGenerator\n",
    "from scripts.jobs.networks.conv_classifier import TrainConvClassifierModel\n",
    "\n",
    "model_name = 'pop_nuts'\n",
    "\n",
    "train_dataset = CreateTFDatasetFromCompositeGenerator(model_name + '_train', 2, batch_size = 8, window_size = 100)\n",
    "test_dataset = CreateTFDatasetFromCompositeGenerator(model_name + '_test', 2, batch_size = 8, window_size = 100)\n",
    "\n",
    "model, history = TrainConvClassifierModel(train_dataset, test_dataset, num_epochs = 10, steps_per_epoch = 1000)  # int(round(500000 / 64, 0)))\n",
    "model.save('/mnt/share/mnt/RESEARCH/SATELLITE/WORK/' + model_name + '_model') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 1/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 24405442.0000 - mae: 0.4930 - accuracy: 0.5070 - val_loss: 30355422.0000 - val_mae: 0.4900 - val_accuracy: 0.5100\nEpoch 2/100\n1000/1000 [==============================] - 11s 11ms/step - loss: 75865240.0000 - mae: 0.4840 - accuracy: 0.5160 - val_loss: 95351328.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 3/100\n1000/1000 [==============================] - 8s 8ms/step - loss: 166770816.0000 - mae: 0.4590 - accuracy: 0.5410 - val_loss: 244721296.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 4/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 180352768.0000 - mae: 0.4310 - accuracy: 0.5690 - val_loss: 194243712.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 5/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 229351104.0000 - mae: 0.4370 - accuracy: 0.5630 - val_loss: 164159984.0000 - val_mae: 0.3300 - val_accuracy: 0.6700\nEpoch 6/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 262420960.0000 - mae: 0.3940 - accuracy: 0.6060 - val_loss: 447335296.0000 - val_mae: 0.3900 - val_accuracy: 0.6100\nEpoch 7/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 550770240.0000 - mae: 0.4490 - accuracy: 0.5510 - val_loss: 1169060864.0000 - val_mae: 0.5400 - val_accuracy: 0.4600\nEpoch 8/100\n1000/1000 [==============================] - 9s 9ms/step - loss: 705617472.0000 - mae: 0.4570 - accuracy: 0.5430 - val_loss: 559210752.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 9/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 708887424.0000 - mae: 0.4220 - accuracy: 0.5780 - val_loss: 917166144.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 10/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 851486848.0000 - mae: 0.4220 - accuracy: 0.5780 - val_loss: 1295773696.0000 - val_mae: 0.5500 - val_accuracy: 0.4500\nEpoch 11/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 907118464.0000 - mae: 0.4490 - accuracy: 0.5510 - val_loss: 469570112.0000 - val_mae: 0.3600 - val_accuracy: 0.6400\nEpoch 12/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 842392192.0000 - mae: 0.4220 - accuracy: 0.5780 - val_loss: 593959296.0000 - val_mae: 0.3400 - val_accuracy: 0.6600\nEpoch 13/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 890902080.0000 - mae: 0.4070 - accuracy: 0.5930 - val_loss: 727230272.0000 - val_mae: 0.3800 - val_accuracy: 0.6200\nEpoch 14/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 897635584.0000 - mae: 0.3990 - accuracy: 0.6010 - val_loss: 1223953664.0000 - val_mae: 0.3500 - val_accuracy: 0.6500\nEpoch 15/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1434736256.0000 - mae: 0.4290 - accuracy: 0.5710 - val_loss: 873501568.0000 - val_mae: 0.3400 - val_accuracy: 0.6600\nEpoch 16/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1383126272.0000 - mae: 0.4070 - accuracy: 0.5930 - val_loss: 1923601920.0000 - val_mae: 0.5000 - val_accuracy: 0.5000\nEpoch 17/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1384875392.0000 - mae: 0.4030 - accuracy: 0.5970 - val_loss: 1209696128.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 18/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 932900416.0000 - mae: 0.3410 - accuracy: 0.6590 - val_loss: 1002424512.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 19/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 962494464.0000 - mae: 0.3560 - accuracy: 0.6440 - val_loss: 1186558848.0000 - val_mae: 0.4300 - val_accuracy: 0.5700\nEpoch 20/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 963899520.0000 - mae: 0.3270 - accuracy: 0.6730 - val_loss: 971308800.0000 - val_mae: 0.4200 - val_accuracy: 0.5800\nEpoch 21/100\n1000/1000 [==============================] - 8s 8ms/step - loss: 1114843520.0000 - mae: 0.3620 - accuracy: 0.6380 - val_loss: 1420945152.0000 - val_mae: 0.4500 - val_accuracy: 0.5500\nEpoch 22/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1143727488.0000 - mae: 0.3380 - accuracy: 0.6620 - val_loss: 2168680960.0000 - val_mae: 0.5000 - val_accuracy: 0.5000\nEpoch 23/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1732682112.0000 - mae: 0.3640 - accuracy: 0.6360 - val_loss: 2109373440.0000 - val_mae: 0.4600 - val_accuracy: 0.5400\nEpoch 24/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1551815552.0000 - mae: 0.3580 - accuracy: 0.6420 - val_loss: 1394464256.0000 - val_mae: 0.3700 - val_accuracy: 0.6300\nEpoch 25/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1452895104.0000 - mae: 0.3350 - accuracy: 0.6650 - val_loss: 1176673408.0000 - val_mae: 0.3300 - val_accuracy: 0.6700\nEpoch 26/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1450004224.0000 - mae: 0.3640 - accuracy: 0.6360 - val_loss: 1400705152.0000 - val_mae: 0.3700 - val_accuracy: 0.6300\nEpoch 27/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1513517696.0000 - mae: 0.3630 - accuracy: 0.6370 - val_loss: 1583291136.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 28/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1448749824.0000 - mae: 0.3370 - accuracy: 0.6630 - val_loss: 1563713920.0000 - val_mae: 0.3700 - val_accuracy: 0.6300\nEpoch 29/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1477589504.0000 - mae: 0.3350 - accuracy: 0.6650 - val_loss: 1188095744.0000 - val_mae: 0.2800 - val_accuracy: 0.7200\nEpoch 30/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1733371264.0000 - mae: 0.3430 - accuracy: 0.6570 - val_loss: 2178352896.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 31/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1762964608.0000 - mae: 0.3770 - accuracy: 0.6230 - val_loss: 2490612736.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 32/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1500507264.0000 - mae: 0.3110 - accuracy: 0.6890 - val_loss: 2597060096.0000 - val_mae: 0.4200 - val_accuracy: 0.5800\nEpoch 33/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1528264960.0000 - mae: 0.3270 - accuracy: 0.6730 - val_loss: 1506765824.0000 - val_mae: 0.2500 - val_accuracy: 0.7500\nEpoch 34/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 1752352384.0000 - mae: 0.3330 - accuracy: 0.6670 - val_loss: 2321078272.0000 - val_mae: 0.3900 - val_accuracy: 0.6100\nEpoch 35/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1575776384.0000 - mae: 0.3210 - accuracy: 0.6790 - val_loss: 2347649024.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 36/100\n1000/1000 [==============================] - 13s 13ms/step - loss: 1392330880.0000 - mae: 0.3040 - accuracy: 0.6960 - val_loss: 2673894400.0000 - val_mae: 0.3900 - val_accuracy: 0.6100\nEpoch 37/100\n1000/1000 [==============================] - 9s 9ms/step - loss: 1608411136.0000 - mae: 0.3150 - accuracy: 0.6850 - val_loss: 1899058432.0000 - val_mae: 0.3500 - val_accuracy: 0.6500\nEpoch 38/100\n1000/1000 [==============================] - 12s 12ms/step - loss: 1636952832.0000 - mae: 0.3250 - accuracy: 0.6750 - val_loss: 1810108416.0000 - val_mae: 0.3100 - val_accuracy: 0.6900\nEpoch 39/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 1699395840.0000 - mae: 0.3240 - accuracy: 0.6760 - val_loss: 2272480512.0000 - val_mae: 0.4200 - val_accuracy: 0.5800\nEpoch 40/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2047530496.0000 - mae: 0.3540 - accuracy: 0.6460 - val_loss: 2880227328.0000 - val_mae: 0.3900 - val_accuracy: 0.6100\nEpoch 41/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 1820878848.0000 - mae: 0.3020 - accuracy: 0.6980 - val_loss: 3113914112.0000 - val_mae: 0.4300 - val_accuracy: 0.5700\nEpoch 42/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1880669696.0000 - mae: 0.3160 - accuracy: 0.6840 - val_loss: 2618016512.0000 - val_mae: 0.4500 - val_accuracy: 0.5500\nEpoch 43/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1969684224.0000 - mae: 0.3200 - accuracy: 0.6800 - val_loss: 2224124928.0000 - val_mae: 0.3700 - val_accuracy: 0.6300\nEpoch 44/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 1800978432.0000 - mae: 0.3120 - accuracy: 0.6880 - val_loss: 2335230720.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 45/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2015247232.0000 - mae: 0.3140 - accuracy: 0.6860 - val_loss: 4617916416.0000 - val_mae: 0.5200 - val_accuracy: 0.4800\nEpoch 46/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2002090368.0000 - mae: 0.2990 - accuracy: 0.7010 - val_loss: 3553343232.0000 - val_mae: 0.4800 - val_accuracy: 0.5200\nEpoch 47/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2687328256.0000 - mae: 0.3580 - accuracy: 0.6420 - val_loss: 2478118400.0000 - val_mae: 0.3600 - val_accuracy: 0.6400\nEpoch 48/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2284401152.0000 - mae: 0.3600 - accuracy: 0.6400 - val_loss: 3677449472.0000 - val_mae: 0.5000 - val_accuracy: 0.5000\nEpoch 49/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2895770624.0000 - mae: 0.3650 - accuracy: 0.6350 - val_loss: 3457230336.0000 - val_mae: 0.4300 - val_accuracy: 0.5700\nEpoch 50/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2482271744.0000 - mae: 0.3560 - accuracy: 0.6440 - val_loss: 2875843584.0000 - val_mae: 0.3300 - val_accuracy: 0.6700\nEpoch 51/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2399164672.0000 - mae: 0.3190 - accuracy: 0.6810 - val_loss: 3059785472.0000 - val_mae: 0.3800 - val_accuracy: 0.6200\nEpoch 52/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2296367616.0000 - mae: 0.3490 - accuracy: 0.6510 - val_loss: 2071644544.0000 - val_mae: 0.3500 - val_accuracy: 0.6500\nEpoch 53/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2376674048.0000 - mae: 0.3170 - accuracy: 0.6830 - val_loss: 5924124672.0000 - val_mae: 0.5000 - val_accuracy: 0.5000\nEpoch 54/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2377855744.0000 - mae: 0.3240 - accuracy: 0.6760 - val_loss: 4642215936.0000 - val_mae: 0.4900 - val_accuracy: 0.5100\nEpoch 55/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2197898496.0000 - mae: 0.3130 - accuracy: 0.6870 - val_loss: 4049951232.0000 - val_mae: 0.4600 - val_accuracy: 0.5400\nEpoch 56/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2283119872.0000 - mae: 0.3210 - accuracy: 0.6790 - val_loss: 3363548416.0000 - val_mae: 0.3900 - val_accuracy: 0.6100\nEpoch 57/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2418980608.0000 - mae: 0.3030 - accuracy: 0.6970 - val_loss: 3345515520.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 58/100\n1000/1000 [==============================] - 8s 8ms/step - loss: 2232112640.0000 - mae: 0.3350 - accuracy: 0.6650 - val_loss: 2934264064.0000 - val_mae: 0.3200 - val_accuracy: 0.6800\nEpoch 59/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2436113920.0000 - mae: 0.3150 - accuracy: 0.6850 - val_loss: 3990052096.0000 - val_mae: 0.4700 - val_accuracy: 0.5300\nEpoch 60/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2007282816.0000 - mae: 0.2680 - accuracy: 0.7320 - val_loss: 3690764032.0000 - val_mae: 0.3400 - val_accuracy: 0.6600\nEpoch 61/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2280631808.0000 - mae: 0.3120 - accuracy: 0.6880 - val_loss: 3285690880.0000 - val_mae: 0.4200 - val_accuracy: 0.5800\nEpoch 62/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2423479296.0000 - mae: 0.3270 - accuracy: 0.6730 - val_loss: 4841724928.0000 - val_mae: 0.4600 - val_accuracy: 0.5400\nEpoch 63/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2705147648.0000 - mae: 0.3300 - accuracy: 0.6700 - val_loss: 3427475200.0000 - val_mae: 0.3800 - val_accuracy: 0.6200\nEpoch 64/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2755392768.0000 - mae: 0.3250 - accuracy: 0.6750 - val_loss: 5093710336.0000 - val_mae: 0.4400 - val_accuracy: 0.5600\nEpoch 65/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2791555584.0000 - mae: 0.3030 - accuracy: 0.6970 - val_loss: 4524663296.0000 - val_mae: 0.4900 - val_accuracy: 0.5100\nEpoch 66/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3149000192.0000 - mae: 0.3410 - accuracy: 0.6590 - val_loss: 3589179648.0000 - val_mae: 0.3600 - val_accuracy: 0.6400\nEpoch 67/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2956986112.0000 - mae: 0.3370 - accuracy: 0.6630 - val_loss: 3966179840.0000 - val_mae: 0.3700 - val_accuracy: 0.6300\nEpoch 68/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2943429632.0000 - mae: 0.3390 - accuracy: 0.6610 - val_loss: 4650616320.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 69/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2530484992.0000 - mae: 0.2870 - accuracy: 0.7130 - val_loss: 4768596480.0000 - val_mae: 0.4500 - val_accuracy: 0.5500\nEpoch 70/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2589456896.0000 - mae: 0.3190 - accuracy: 0.6810 - val_loss: 4297604096.0000 - val_mae: 0.4700 - val_accuracy: 0.5300\nEpoch 71/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2531534592.0000 - mae: 0.2980 - accuracy: 0.7020 - val_loss: 4436670976.0000 - val_mae: 0.3700 - val_accuracy: 0.6300\nEpoch 72/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 2703398912.0000 - mae: 0.2820 - accuracy: 0.7180 - val_loss: 2901337600.0000 - val_mae: 0.3600 - val_accuracy: 0.6400\nEpoch 73/100\n1000/1000 [==============================] - 9s 9ms/step - loss: 2587785216.0000 - mae: 0.3070 - accuracy: 0.6930 - val_loss: 2926519808.0000 - val_mae: 0.3200 - val_accuracy: 0.6800\nEpoch 74/100\n1000/1000 [==============================] - 15s 15ms/step - loss: 2712216832.0000 - mae: 0.2820 - accuracy: 0.7180 - val_loss: 7056815616.0000 - val_mae: 0.4400 - val_accuracy: 0.5600\nEpoch 75/100\n1000/1000 [==============================] - 10s 10ms/step - loss: 3215670016.0000 - mae: 0.3210 - accuracy: 0.6790 - val_loss: 4488337408.0000 - val_mae: 0.4000 - val_accuracy: 0.6000\nEpoch 76/100\n1000/1000 [==============================] - 8s 8ms/step - loss: 3780584192.0000 - mae: 0.3510 - accuracy: 0.6490 - val_loss: 7888182272.0000 - val_mae: 0.5000 - val_accuracy: 0.5000\nEpoch 77/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 3322027776.0000 - mae: 0.2910 - accuracy: 0.7090 - val_loss: 3031421440.0000 - val_mae: 0.3400 - val_accuracy: 0.6600\nEpoch 78/100\n1000/1000 [==============================] - 12s 12ms/step - loss: 3747704320.0000 - mae: 0.3490 - accuracy: 0.6510 - val_loss: 5873013248.0000 - val_mae: 0.3400 - val_accuracy: 0.6600\nEpoch 79/100\n1000/1000 [==============================] - 9s 9ms/step - loss: 3443124224.0000 - mae: 0.3050 - accuracy: 0.6950 - val_loss: 7687505408.0000 - val_mae: 0.5200 - val_accuracy: 0.4800\nEpoch 80/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2923976448.0000 - mae: 0.3010 - accuracy: 0.6990 - val_loss: 4507798016.0000 - val_mae: 0.3500 - val_accuracy: 0.6500\nEpoch 81/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 3202275840.0000 - mae: 0.3260 - accuracy: 0.6740 - val_loss: 4581596160.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 82/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3525244416.0000 - mae: 0.3270 - accuracy: 0.6730 - val_loss: 6784010240.0000 - val_mae: 0.4900 - val_accuracy: 0.5100\nEpoch 83/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3544015872.0000 - mae: 0.3280 - accuracy: 0.6720 - val_loss: 4207228928.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 84/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3505417984.0000 - mae: 0.3080 - accuracy: 0.6920 - val_loss: 8309134336.0000 - val_mae: 0.4800 - val_accuracy: 0.5200\nEpoch 85/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3363715840.0000 - mae: 0.3110 - accuracy: 0.6890 - val_loss: 5031490560.0000 - val_mae: 0.3200 - val_accuracy: 0.6800\nEpoch 86/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 2834117632.0000 - mae: 0.2660 - accuracy: 0.7340 - val_loss: 7756086784.0000 - val_mae: 0.4900 - val_accuracy: 0.5100\nEpoch 87/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 2791158528.0000 - mae: 0.2660 - accuracy: 0.7340 - val_loss: 6233604096.0000 - val_mae: 0.4200 - val_accuracy: 0.5800\nEpoch 88/100\n1000/1000 [==============================] - 5s 5ms/step - loss: 3353230848.0000 - mae: 0.3150 - accuracy: 0.6850 - val_loss: 4070776576.0000 - val_mae: 0.3300 - val_accuracy: 0.6700\nEpoch 89/100\n1000/1000 [==============================] - 9s 9ms/step - loss: 3147576576.0000 - mae: 0.2670 - accuracy: 0.7330 - val_loss: 6508903936.0000 - val_mae: 0.4500 - val_accuracy: 0.5500\nEpoch 90/100\n1000/1000 [==============================] - 7s 7ms/step - loss: 3699084288.0000 - mae: 0.3350 - accuracy: 0.6650 - val_loss: 4415166464.0000 - val_mae: 0.3800 - val_accuracy: 0.6200\nEpoch 91/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3245857792.0000 - mae: 0.2890 - accuracy: 0.7110 - val_loss: 5884650496.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 92/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3237999360.0000 - mae: 0.3140 - accuracy: 0.6860 - val_loss: 6581639168.0000 - val_mae: 0.4100 - val_accuracy: 0.5900\nEpoch 93/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3941565952.0000 - mae: 0.3180 - accuracy: 0.6820 - val_loss: 8102488064.0000 - val_mae: 0.4800 - val_accuracy: 0.5200\nEpoch 94/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3858623744.0000 - mae: 0.3320 - accuracy: 0.6680 - val_loss: 6161431040.0000 - val_mae: 0.5000 - val_accuracy: 0.5000\nEpoch 95/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3890680832.0000 - mae: 0.2950 - accuracy: 0.7050 - val_loss: 8563448320.0000 - val_mae: 0.4600 - val_accuracy: 0.5400\nEpoch 96/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 4641018368.0000 - mae: 0.3360 - accuracy: 0.6640 - val_loss: 6736457728.0000 - val_mae: 0.4400 - val_accuracy: 0.5600\nEpoch 97/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 4295755776.0000 - mae: 0.3190 - accuracy: 0.6810 - val_loss: 5885660160.0000 - val_mae: 0.4700 - val_accuracy: 0.5300\nEpoch 98/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3549933056.0000 - mae: 0.2650 - accuracy: 0.7350 - val_loss: 6144652288.0000 - val_mae: 0.3600 - val_accuracy: 0.6400\nEpoch 99/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 3431539968.0000 - mae: 0.2890 - accuracy: 0.7110 - val_loss: 7100011520.0000 - val_mae: 0.5100 - val_accuracy: 0.4900\nEpoch 100/100\n1000/1000 [==============================] - 6s 6ms/step - loss: 4200047360.0000 - mae: 0.3150 - accuracy: 0.6850 - val_loss: 5651911680.0000 - val_mae: 0.3600 - val_accuracy: 0.6400\nINFO:tensorflow:Assets written to: /mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_dem_ww_nuts_linear_model/assets\n"
    }
   ],
   "source": [
    "from scripts.jobs.dataset_creation import CreateTFDatasetFromInMemoryGenerator, InMemoryStridedArrayGenerator, create_generator_sequence, SequenceSeparator\n",
    "from scripts.jobs.networks.conv_classifier import TrainConvClassifierModel\n",
    "import scripts.jobs.dataset_creation as dataset_creation\n",
    "from scripts.jobs.networks.network_factory import build_network\n",
    "import tensorflow as tf\n",
    "\n",
    "raster_ww_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/ww_aggr_rst.tif'\n",
    "raster_dem_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/dem_aggr_rst.tif'\n",
    "raster_pop_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_rst.tif'\n",
    "raster_nuts_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/nuts_rst.tif'\n",
    "\n",
    "model_name = 'pop_dem_ww_nuts_linear'\n",
    "window_size = 101\n",
    "train_overfit_size = 1000\n",
    "\n",
    "rasters = {\n",
    "    'pop': {\n",
    "        'type': 'input',\n",
    "        'data': dataset_creation.PreprocessForResnet(dataset_creation.PreProcessLogarithmPopulationRaster(dataset_creation.PreProcessPopulationRaster(dataset_creation.ReadRasterFile(raster_pop_fn)))),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'dem': {\n",
    "        'type': 'input',\n",
    "        'data': dataset_creation.PreprocessForResnet(dataset_creation.PreprocessDEMRaster(dataset_creation.ReadRasterFile(raster_dem_fn))),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'ww': {\n",
    "        'type': 'input',\n",
    "        'data': dataset_creation.PreprocessForResnet(dataset_creation.PreProcessWWRaster(dataset_creation.ReadRasterFile(raster_ww_fn))),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'nuts': {\n",
    "        'type': 'output',\n",
    "        'data': dataset_creation.PreProcessBorderRaster(dataset_creation.ReadRasterFile(raster_nuts_fn), bad_value=-1),\n",
    "        'bad_value_threshold': -1\n",
    "    }\n",
    "}\n",
    "\n",
    "full_generator_sequence = create_generator_sequence(rasters, window_size = window_size, padding_size = 140)\n",
    "sequence_separator = SequenceSeparator(rasters, window_size = window_size)\n",
    "generator_sequences = sequence_separator(full_generator_sequence)\n",
    "train_sizes = [int(len(generator_sequence) * 0.8) for generator_sequence in generator_sequences]\n",
    "total_size = sum([len(generator_sequence)for generator_sequence in generator_sequences])\n",
    "train_overfit_size = total_size\n",
    "\n",
    "train_gen = InMemoryStridedArrayGenerator(\n",
    "    rasters,\n",
    "    window_size = window_size,\n",
    "    generator_sequences = [generator_sequence[0:int(len(generator_sequence) * 0.8 * train_overfit_size/total_size)] for generator_sequence in generator_sequences]\n",
    ")\n",
    "train_dataset = CreateTFDatasetFromInMemoryGenerator(train_gen, batch_size = 64, window_size = window_size, channel_n = len(rasters) - 1)\n",
    "test_gen = InMemoryStridedArrayGenerator(\n",
    "    rasters,\n",
    "    window_size = window_size,\n",
    "    generator_sequences = [generator_sequence[int(len(generator_sequence) * 0.8):] for generator_sequence in generator_sequences]\n",
    ")\n",
    "test_dataset = CreateTFDatasetFromInMemoryGenerator(test_gen, batch_size = 64, window_size = window_size, channel_n = len(rasters) - 1)\n",
    "\n",
    "# internal_model = build_network('simple_cnn', internal_dense_size = 100)\n",
    "# internal_model = build_network('simple_resnet', internal_dense_size = 100, input_size = window_size, channel_n = len(rasters) - 1)\n",
    "internal_model = build_network('linear')\n",
    "\n",
    "model, history = TrainConvClassifierModel(\n",
    "    train_dataset,\n",
    "    test_dataset,\n",
    "    num_epochs = 100,\n",
    "    steps_per_epoch = 1000,\n",
    "    internal_model = internal_model\n",
    ")\n",
    "\n",
    "for i in range(0,0):\n",
    "    train_overfit_size = int(train_overfit_size * 1.2)\n",
    "    if train_overfit_size > total_size:\n",
    "        break\n",
    "    train_gen = InMemoryStridedArrayGenerator(\n",
    "        rasters,\n",
    "        window_size = window_size,\n",
    "        generator_sequences = [generator_sequence[0:int(len(generator_sequence) * 0.8 * train_overfit_size/total_size)] for generator_sequence in generator_sequences]\n",
    "    )\n",
    "    train_dataset = CreateTFDatasetFromInMemoryGenerator(train_gen, batch_size = 64, window_size = window_size, channel_n = len(rasters) - 1)\n",
    "\n",
    "    print(train_overfit_size)\n",
    "    model, history = TrainConvClassifierModel(\n",
    "        train_dataset,\n",
    "        test_dataset,\n",
    "        num_epochs = 10,\n",
    "        steps_per_epoch = 1000,\n",
    "        internal_model = internal_model,\n",
    "        complete_model = model\n",
    "    )\n",
    "\n",
    "model.save('/mnt/share/mnt/RESEARCH/SATELLITE/WORK/' + model_name + '_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0.0]\n"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 720x720 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"574.678125pt\" version=\"1.1\" viewBox=\"0 0 577.725 574.678125\" width=\"577.725pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2020-09-05T10:15:09.425626</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.0, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 574.678125 \nL 577.725 574.678125 \nL 577.725 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 550.8 \nL 570.525 550.8 \nL 570.525 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#pd248acfe39)\">\n    <image height=\"544\" id=\"image1770640682\" transform=\"scale(1 -1)translate(0 -544)\" width=\"544\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-6.8\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mfb333fbf53\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"35.161364\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(31.980114 565.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"117.525\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <g transform=\"translate(114.34375 565.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"199.888636\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <g transform=\"translate(193.526136 565.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"282.252273\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(275.889773 565.398438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"364.615909\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <g transform=\"translate(358.253409 565.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"446.979545\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(440.617045 565.398438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"529.343182\" xlink:href=\"#mfb333fbf53\" y=\"550.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 30 -->\n      <g transform=\"translate(522.980682 565.398438)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m11aa4dd163\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"15.436364\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 19.235582)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"97.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 101.599219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"180.163636\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 183.962855)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"262.527273\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 266.326491)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"344.890909\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 348.690128)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"427.254545\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 431.053764)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m11aa4dd163\" y=\"509.618182\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 513.417401)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 550.8 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 570.525 550.8 \nL 570.525 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 550.8 \nL 570.525 550.8 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 570.525 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pd248acfe39\">\n   <rect height=\"543.6\" width=\"543.6\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkEAAAI/CAYAAABwLA0cAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy86wFpkAAAACXBIWXMAAAsTAAALEwEAmpwYAAAhRElEQVR4nO3de7ClWVkf4N9Ld88McgmD4mRkUEdiRakYB9NSXuMtApoLknhDY0BNxkrEwqApCcSABgwqoOUlWENBwGQUiKKAoRRqgqiFQQZBbuOFUYg9DjMiQ2QAZ7pPr/zRe8rOVPf06X7XuXSv56nq6nO+c9613732+r79O9/Z+zs1xggAwGrutdcNAADsBSEIAFiSEAQALEkIAgCWJAQBAEsSggCAJR3czRurQzVyybnXH5rQw9EJY3Rd2qy/bUIP923W33tCD3+eatUfmNDDQ9K7RMSMC0y8b8IYe+0+E8b4G836P5vQQ9cDJ4xx/2b9jGPcTRPGYI5Pbtb/nyldXABuzwfGGA+6++ZdDUG5JMnnnHv5ZROecY70nnen+Mpm/csn9PD3mvWfNaGHn8rFrfruk0WSPD1/1aqf8YRz9YQx9tpnTxjjUc36p++DS549asLx5ZHN+pv7LeSpE8Zo2weP537wtGb9d0zpYo/NWAu/deqfN/06DABYkhAEACypFYKq6tFV9QdV9Z6qesqspgAAdto5h6CqOpDkp5N8VZKHJXlcVT1sVmMAADupcyboEUneM8b44zHGnUlemuQxc9oCANhZnRD04CR/etLnRzbbAAD2vR1/i3xVXZ273gXce0c0AMA0nTNBNyV5yEmfX5FTXGNrjHHNGOPwGOPwlKsdAgBM0AlBb07y6VV1ZVVdlOQbk7xqTlsAADvrnH8dNsY4VlVPTPJrOfEXDF40xnjXtM4AAHZQ6zVBY4zXJHnNpF4AAHaNK0YDAEsSggCAJQlBAMCSdvw6QTMdqb3uIHnohDFe3h1g9Hu4vDmXP9VvIcnxVvWjs9XuoHvpqre3O7gwvHHGGBPWddfPN+svmtDDseY8PHVCD+wfH2quhx9qHuufug/2y53kTBAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJB/e6gd32mOZdfmXu229ifLRXX3e2W3hpe4S+p43jrfors9Xu4ZuqV//sdgdJRrO+eR+S5Eua9W/o3ocJvmHCGA9s1t9vwjy8v1n/zf0Wcu2EMUh/305yS7P+Y/0WLmjOBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAs6eCu3+I499Jvm3Dzj+k0kORTcme7h5+o4+0x2sbF3QHaLRxtzuUftDtIvrdZ/5H+NOwLb7gA7sfLJozxJc36T5rQw+3N+tdM6IH943ndAbr7dnUbmNDDDnImCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsKSDe93A2fjaCWOMbLXqPzMfbfdw6ejV39buIEn15mFGfv6R5jxM0ezhCya0cEX16o9M6CHNHr5kwmP5qGb9r/VbyL9p1v/TCT28YsIYzPG9zfo/mNDDqyeM0TLlOH1gxiBNp37OcyYIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYEkHd/PGPj7JYxr1f1H9Ho6NXv37+y3ktu4AE+YhOdaq/ooJHVw35X40NdfDG+d00dO8D0nyb5v1D+y3kAc178ejJqynNzTrX9FvgUn+w4QxHtqsf8CEHl49YYy91905e89X98SZIABgSUIQALAkIQgAWJIQBAAsqfXC6Kp6b5IPJ9lKcmyMcXhGUwAAO23Gu8O+bIzxgQnjAADsGr8OAwCW1A1BI8lrq+otVXX1jIYAAHZD99dhXzTGuKmqPjHJ66rq98cYv3HyN2zC0dVJcp+Lm7cGADBJ60zQGOOmzf+3JvmlJI84xfdcM8Y4PMY4fMmhzq0BAMxzziGoqu5TVfe76+Mkj0zyzlmNAQDspM6vwy5L8ktVddc4PzfG+NUpXQEA7LBzDkFjjD9O8tkTewEA2DXeIg8ALEkIAgCWJAQBAEua8Wcztu0vkryoUf8nE3r4xGb9yyb00DZmDNK7XsF1OTqjib1Xe93A/vCH3XmYsCb/WXNN3pHj/SayNWEM9oOfnjDGbc11/V0Tenhos/7GbgMT9u2r61ir/vP7LeRbT7PdmSAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJR3c6wbOxuvHXnewT9SEMYb8e6F4woQxXrwP9q3H5kCr/rdnNDG2evUz9s0LwHdOGONDzfprx8dN6KK3Hn4yxyf0cHTCGA0T1vRHm8eXN+7gfuWZEABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsKSDe93AkqpZP2Y0cceMQdgHrpwwxtOa9c/KgXYPv5atVv1rx9F2D+198wLxxc36z5vQwzvbx7neejqhe55gysH6vPffq3l8uNeMx/I0Q+/YyAAA+5gQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSQf3uoEljb1uIEkubtbfMaWL894+eCz/74Qx/rw7wOj/PPU//Ey2b/xms/4LJ+wXr+kOMCYco6p7nDzebuEJzbm8pHr1PzNlt9zqlTfvwz1x1AEAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACzp4G7e2IEk92/UP35CD69u1t8xoYcjOdCqf/iE7PrWHG+P0debh9RWu4OnNevf1e4g+eVm/fMm9JDRHWDGemo3cWHoTkPtfQ/PnvBQfl2z/h3d40uS7hH/+yZ08GnNx/N93QZmrKd9zJkgAGBJQhAAsCQhCABY0hlDUFW9qKpurap3nrTtgVX1uqr6o83/l+5smwAAc23nTNCLkzz6btuekuS6McanJ7lu8zkAwHnjjCFojPEbST54t82PSfKSzccvSfI1c9sCANhZ5/qaoMvGGDdvPn5/kssm9QMAsCva1wkaY4yqOu1VIarq6iRXJ8m9Lu7eGgDAHOd6JuiWqro8STb/33q6bxxjXDPGODzGOFyHzvHWAAAmO9cQ9Kr89QWcH5/klXPaAQDYHdt5i/zPJ/ntJH+7qo5U1bcneXaSr6yqP0ryDzafAwCcN874mqAxxuNO86WvmNwLAMCuccVoAGBJQhAAsCQhCABYUvs6QWdjK8ltjfpHTOih+y79H81FE7o40Kp+a057Waaz8FcTxujqZfBnjq12Bw9r1n9Ku4PkDc362yYsh+c36/91qt9Ec79IjvVbmLFrdekhSfJPmkvqb05Ykz/ZnIcfbneQ/m6xH7TX04zr6xw95VZnggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEs6uJs3diDJ/ce51/9+DrR7+JPa6g0wjrd7+IpmD9eleR+S9B/6Gfn5zlb1AyZ08MFm/asn9HBbd4Dq93BRY79Mks/MsXYPN3THmDAPVzTn4d8365P+mvz+CT2053JCD9c16z88YU227YfTDN3HcsJ+9S3N9fDf0n/ePZ398BABAOw6IQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJIO7uaNbSW5rVH/g7Ma6ahj7SGu291pP43e/bhiQgdHmvVPnNADJ7y7WX/DlC6aRn+IJzXHODJh375vNZsY1e4hozuZW+0WXjwO9Aaofg/74lA9YV13fN6E239Ueo/lJ09Y0s86zXZnggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEs6uNcNnJXa2usOknHRhEGO98prQgs51Ko+MiU/39Gq/r4JHfRmIXnmhB72gxc16z9rQg/v6A4w+j38u/aKmLBfjO5x7li/h/2gmge6GYeo7rF2wppMLmnW99bTN+Vo8/aTI80entXu4PScCQIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABY0sFdv8Xa9Vuc7ELJjcf3uoG2z5wwxqFm/TdP6OHaCWN03dbcL28bM7roPhozDi5bzfqjE3o40KzvzmMy5350HeuVn/fPNXfprcnndo/1E/btp3QH2MHH8kJ5RgcAOCtCEACwJCEIAFiSEAQALOmMIaiqXlRVt1bVO0/a9oyquqmq3rb599U72yYAwFzbORP04iSPPsX2HxtjXLX595q5bQEA7KwzhqAxxm8k+eAu9AIAsGs6rwl6YlW9ffPrskundQQAsAvONQQ9P8lDk1yV5OYkzz3dN1bV1VV1fVVdvy+uvwUAkHMMQWOMW8YYW2OM40lekOQR9/C914wxDo8xDk+5kCkAwATnFIKq6vKTPn1sknee7nsBAPajM/7tsKr6+SRfmuQTqupIkqcn+dKquion/qrIe5N8x861CAAw3xlD0BjjcafY/MId6AUAYNe4YjQAsCQhCABYkhAEACzpjK8Jmm7s+i3+/6o7wPF2C1/QHOON7Q6SS8dWq/7rqlefJNfkolb9r4/+NRc+rT7Sqr+23QF/rXkhsZpwDY7mfjHDpc2fTW/LgQld9B6Ln2gfZ5OjzTFu7LeQ/9IdYMI8ZPQei+9pPud+W6/8hBnzsEOcCQIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYUo0xdu/G7lcjV3UGmNDE7t3dfe2nm3P5wXGo3cP3dzN4zVgQfzVhDKbo7psXyL79vGb9/Sf08C+7A0z48fqzDvTq39FvYX+sqe5h7viULnr2w+mWX89bxhiH7755P7QGALDrhCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJR3czRu7OMkVjfobR7+Hf9Ss/5V+C/vCnzTn8jlT8vPxZv3RCT1cAGqvG0gyYd/khCc3679hwq55abP+tgk9vKM/xN7bD/tmHtisv6TfwvizXv0Onq5xJggAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSQd388buSHJjo/6aCT0catY/dkIPH2vWP3FCD89pj3DHhC7gJGOvG5ihe4RJnpHjrfq31la7h9vaI0zQXQ/Vb+Fzm/Vv7rfQvx/VO1b/8IT98vbmffhPO3hscCYIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwpIN73cDZuHPCGPebMEbXg5r1PzvhYfsXGc0Rtto9pPpDsE90l1PSXg+fO6GHJzV7qAk9HGnWf/Xxfg+v7P54PGPfbs7lT0x4LN7brH/zjP2i7SOt6tua9Unypn0xD6fmTBAAsCQhCABYkhAEACzpjCGoqh5SVa+vqndX1buq6kmb7Q+sqtdV1R9t/r9059sFAJhjO2eCjiX5njHGw5J8XpLvrKqHJXlKkuvGGJ+e5LrN5wAA54UzhqAxxs1jjN/dfPzhJDckeXCSxyR5yebbXpLka3aoRwCA6c7qNUFV9alJHp7kTUkuG2PcvPnS+5NcNrc1AICds+0QVFX3TfKLSb57jPGXJ39tjDFymqs6VNXVVXV9VV2fo61eAQCm2VYIqqpDORGArh1jvGKz+Zaqunzz9cuT3Hqq2jHGNWOMw2OMwzk0o2UAgL7tvDuskrwwyQ1jjOed9KVXJXn85uPHJ3nl/PYAAHbGdv7+whcm+ZYk76iqt222PTXJs5O8vKq+Pcn7knz9jnQIALADzhiCxhi/ldP/JZivmNsOAMDucMVoAGBJQhAAsCQhCABY0nZeGD3Paa8mtD3vmdDC65p3+Vurnxtvz52t+jfnWLuHttO9Soyztx/msrFfTtPs4c0TWvi9Zg+PnHAxtE9sroePTlhPz2qO8bR+C+394gMT1vTzumPMOM2wx8eHZ884NjTHeMKEeXzxabY7EwQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFjSwb1u4Gz8+JRRRqv6lTk+pQu4kDxhwhgPr179k3q7dpLkR3OgVX9ltto93NKchx9o1idJZoyxx35wwqH6Cb3lkKMT5vHaZv2lzf3iaRPuw7HmY3FgB592nQkCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWNLBvW5g19XWXnewP9ReNzDBmDCGeZgyxpUTWrj3jPvR1lsQH8ol7Q5+Pc1j1L2OtnvYF/bBeuiu6wdP6OHaZv1tzWPc9x5vNpDkHzbrD07o4XScCQIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACzp4F43cFZqrxvYJ8zDPKNZP+Ox6PbQrZ8wxtMntPAFE8boemSOteqfWhMWRB3vj9E1Y0117YN9c6s5xh/OOM2wD5ZD1//cD+vpNJwJAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFjSwV29tdr8gwvEk0Z/jIuaY/xov4UkFzfrj7c7eGOOtur/cy5q93Cw7mzVv/ZevfuQ5IL40fTHJxznb2wuqZ+c0MPvNOt/td9CX/cYNeEY1/V9uXd7jB/Ox065/QLY3QAAzp4QBAAsSQgCAJZ0xhBUVQ+pqtdX1bur6l1V9aTN9mdU1U1V9bbNv6/e+XYBAObYzgujjyX5njHG71bV/ZK8papet/naj40xnrNz7QEA7IwzhqAxxs1Jbt58/OGquiHJg3e6MQCAnXRWrwmqqk9N8vAkb9psemJVvb2qXlRVl85uDgBgp2w7BFXVfZP8YpLvHmP8ZZLnJ3lokqty4kzRc09Td3VVXV9V1zcvAwIAMM22QlBVHcqJAHTtGOMVSTLGuGWMsTXGOJ7kBUkecaraMcY1Y4zDY4zDOTSrbQCAnu28O6ySvDDJDWOM5520/fKTvu2xSd45vz0AgJ2xnXeHfWGSb0nyjqp622bbU5M8rqquyomLar83yXfsQH8AADtiO+8O+62c+i9+vWZ+OwAAu8MVowGAJQlBAMCShCAAYElCEACwpO28O4zZTvUyc/bG6JV/8oQWun+D5r9O6OHGHG/VP7NZP8PH36vfw43dAS6QffvJzfpLJiyH+3bncsKP+L/aHWOr38Oeax4jk+RfNes/bgcn0pkgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUd3NVbG5t/56pmNXJ+u2LCGEe6A3QexwvIjRPGuLJZf2BCD1+So636Z07ooXtH/rCOtVu4pTvAjGNUd4wJ++bzugPMOD5052E/PF/shx62euVX56J2C5+R4636J9ed7R5Ox5kgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkmqMsXs3dr8auWrXbm5n1F43MEn3Yd+9ZbPPHWiP8EPZatV/UruDZCuHWvUvuNfxdg9HDvTm4Ui/BT8W3qU7lzOOD91da8axurseZqzJY8369mPxgO4A+Y91Z6t+Kx9t9/Cs38xbxhiH777dLg8ALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwpIN73cB5Zxzqj1HHmz0c6PcwqjnAHf0eLgj9x+LPckmr/mMTHos7crRVf9mEH6f+d3dJzviRbkwYY6/NmIfuYzHBFzd7+M0Zj+VWs755qE+Sb2zej5e2j1EfadYnP9iciC/bwfXoTBAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABYkhAEACxJCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJB3fzxi4dlUeOi8+5/mXZmtDF0T2uTzK6A1zU7yE1YQyS4+0R3t9cUx+rY+0ePq7549CftztIf79o71f7RPdH0wnz8OPN+vtP6OHO5q51WX/XzC90B5gwDw9t1j+l+Xzx2/lYs4PkDc361+/g05UzQQDAkoQgAGBJQhAAsKQzhqCquqSqfqeqfq+q3lVVP7DZfmVVvamq3lNVL6uqGS9UAQDYFds5E3RHki8fY3x2kquSPLqqPi/JDyf5sTHG30pyW5Jv37EuAQAmO2MIGifcvvn00ObfSPLl+esXz78kydfsRIMAADthW68JqqoDVfW2JLcmeV2SG5N8aIxx13tzjyR58I50CACwA7YVgsYYW2OMq5JckeQRST5juzdQVVdX1fVVdf0dxy6UC3kAAOe7s3p32BjjQ0len+Tzkzygqu662OIVSW46Tc01Y4zDY4zDFx90gT4AYH/YzrvDHlRVD9h8fO8kX5nkhpwIQ1+7+bbHJ3nlDvUIADDddv5sxuVJXlJVB3IiNL18jPErVfXuJC+tqmcmeWuSF+5gnwAAU50xBI0x3p7k4afY/sc58fogAIDzjitGAwBLEoIAgCUJQQDAkmqM3bt2z5X3vdf4gau281rsU/uLHG/38OT2CDPe5t+d8xnZtXs/7pzQA0n6D8WMJdldUvtht+gfHvr348CEHrpmHNK3en8K8omj/2DcP8fO/E334IfaHST/uFn/6gk9dD2heovyULbaPbygu1+de2z4a/8rbxljHL77ZmeCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJYkBAEASxKCAIAlCUEAwJKEIABgSUIQALAkIQgAWJIQBAAsSQgCAJZ0cDdv7HhGPpKj51z/V1O66N7lGbnxeLP+wIQetiaMcf77pmb9B6rfw2snjLHnxt6PcemEFj61+Vi8tbtrJ/3Dw4zHotnET+VYu4MvaNZ/V7uD5ONzcav+1ROOsz/SnMu3pLeoX7wfjk8z9qvTcCYIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwJCEIAFiSEAQALEkIAgCWJAQBAEsSggCAJQlBAMCShCAAYElCEACwpBpj7N6NVf15kvfdw7d8QpIP7FI7FzpzOYd5nMM8zmMu5zCPc5wv8/gpY4wH3X3jroagM6mq68cYh/e6jwuBuZzDPM5hHucxl3OYxznO93n06zAAYElCEACwpP0Wgq7Z6wYuIOZyDvM4h3mcx1zOYR7nOK/ncV+9JggAYLfstzNBAAC7Yt+EoKp6dFX9QVW9p6qestf9nK+q6r1V9Y6qeltVXb/X/ZxPqupFVXVrVb3zpG0PrKrXVdUfbf6/dC97PB+cZh6fUVU3bdbl26rqq/eyx/NBVT2kql5fVe+uqndV1ZM2263Js3AP82hNnqWquqSqfqeqfm8zlz+w2X5lVb1p8/z9sqq6aK973a598euwqjqQ5A+TfGWSI0nenORxY4x372lj56Gqem+Sw2OM8+G6DftKVf39JLcn+dkxxt/ZbPuRJB8cYzx7E84vHWN83172ud+dZh6fkeT2McZz9rK380lVXZ7k8jHG71bV/ZK8JcnXJHlCrMltu4d5/PpYk2elqirJfcYYt1fVoSS/leRJSZ6c5BVjjJdW1c8k+b0xxvP3stft2i9ngh6R5D1jjD8eY9yZ5KVJHrPHPbGYMcZvJPng3TY/JslLNh+/JCcOntyD08wjZ2mMcfMY43c3H384yQ1JHhxr8qzcwzxylsYJt28+PbT5N5J8eZJf2Gw/r9bkfglBD07ypyd9fiQW6bkaSV5bVW+pqqv3upkLwGVjjJs3H78/yWV72cx57olV9fbNr8v8CucsVNWnJnl4kjfFmjxnd5vHxJo8a1V1oKreluTWJK9LcmOSD40xjm2+5bx6/t4vIYh5vmiM8TlJvirJd25+NcEE48Tvjvf+98fnp+cneWiSq5LcnOS5e9rNeaSq7pvkF5N89xjjL0/+mjW5faeYR2vyHIwxtsYYVyW5Iid+i/MZe9tRz34JQTclechJn1+x2cZZGmPctPn/1iS/lBOLlHN3y+Y1BXe9tuDWPe7nvDTGuGVz8Dye5AWxLrdl87qLX0xy7RjjFZvN1uRZOtU8WpM9Y4wPJXl9ks9P8oCqOrj50nn1/L1fQtCbk3z65hXmFyX5xiSv2uOezjtVdZ/NC/9SVfdJ8sgk77znKs7gVUkev/n48UleuYe9nLfuetLeeGysyzPavAj1hUluGGM876QvWZNn4XTzaE2evap6UFU9YPPxvXPizUw35EQY+trNt51Xa3JfvDssSTZvT/zxJAeSvGiM8ay97ej8U1WflhNnf5LkYJKfM4/bV1U/n+RLc+KvIt+S5OlJfjnJy5N8cpL3Jfn6MYYX/d6D08zjl+bErx1Gkvcm+Y6TXtfCKVTVFyX5zSTvSHJ8s/mpOfF6Fmtym+5hHh8Xa/KsVNXfzYkXPh/IiZMoLx9j/ODmueelSR6Y5K1J/vkY446963T79k0IAgDYTfvl12EAALtKCAIAliQEAQBLEoIAgCUJQQDAkoQgAGBJQhAAsCQhCABY0v8DHpsJKe9YAlUAAAAASUVORK5CYII=\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.figure(figsize = (10,10))\n",
    "a = next(train_gen)[0]\n",
    "print(next(train_gen)[1])\n",
    "pyplot.imshow(a, cmap='viridis')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scripts.jobs.dataset_creation as dataset_creation\n",
    "from scripts.jobs.model_prediction import PredictClassifierRaster, WriteResultRaster, FilterPredictionRaster\n",
    "\n",
    "model_name = 'pop_dem_ww_nuts_linear'\n",
    "window_size = 101\n",
    "\n",
    "raster_ww_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/ww_aggr_rst.tif'\n",
    "raster_dem_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/dem_aggr_rst.tif'\n",
    "raster_pop_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_rst.tif'\n",
    "raster_nuts_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/nuts_rst.tif'\n",
    "model = tf.keras.models.load_model('/mnt/share/mnt/RESEARCH/SATELLITE/WORK/' + model_name + '_model') \n",
    "\n",
    "a = dataset_creation.PreprocessForResnet(dataset_creation.PreProcessLogarithmPopulationRaster(dataset_creation.PreProcessPopulationRaster(dataset_creation.ReadRasterFile(raster_pop_fn))))\n",
    "b = dataset_creation.PreprocessForResnet(dataset_creation.PreprocessDEMRaster(dataset_creation.ReadRasterFile(raster_dem_fn)))\n",
    "c = dataset_creation.PreprocessForResnet(dataset_creation.PreProcessWWRaster(dataset_creation.ReadRasterFile(raster_ww_fn)))\n",
    "a = np.stack([a, b, c], axis = -1).astype(np.float32)\n",
    "# a = np.stack([a] * 3, axis = -1)\n",
    "\n",
    "data = PredictClassifierRaster(a, model, stride = window_size, channel_n = 3)\n",
    "\n",
    "out_rst_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/result_' + model_name + '.tif'\n",
    "WriteResultRaster(data, raster_dem_fn, out_rst_fn, channels=0)\n",
    "\n",
    "data = FilterPredictionRaster(dataset_creation.PreProcessBorderRaster(dataset_creation.ReadRasterFile(raster_nuts_fn), bad_value=-1), data)\n",
    "out_rst_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/result_comparison_' + model_name + '.tif'\n",
    "WriteResultRaster(data, raster_dem_fn, out_rst_fn, channels=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-62c5e10acd9e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mtrain_dataset_generator\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mdataset_creation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInMemoryStridedArrayGeneratorForLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrasters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataset_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mlog_regr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import scripts.jobs.dataset_creation as dataset_creation\n",
    "\n",
    "raster_ww_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/ww_aggr_rst.tif'\n",
    "raster_dem_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/dem_aggr_rst.tif'\n",
    "raster_pop_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_rst.tif'\n",
    "raster_nuts_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/nuts_rst.tif'\n",
    "\n",
    "model_name = 'pop_dem_ww_nuts_linear'\n",
    "window_size = 33\n",
    "training_size = 10000\n",
    "\n",
    "rasters = {\n",
    "    'pop': {\n",
    "        'type': 'input',\n",
    "        'data': dataset_creation.PreprocessForResnet(dataset_creation.PreProcessLogarithmPopulationRaster(dataset_creation.PreProcessPopulationRaster(dataset_creation.ReadRasterFile(raster_pop_fn)))),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'dem': {\n",
    "        'type': 'input',\n",
    "        'data': dataset_creation.PreprocessForResnet(dataset_creation.PreprocessDEMRaster(dataset_creation.ReadRasterFile(raster_dem_fn))),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'ww': {\n",
    "        'type': 'input',\n",
    "        'data': dataset_creation.PreprocessForResnet(dataset_creation.PreProcessWWRaster(dataset_creation.ReadRasterFile(raster_ww_fn))),\n",
    "        'bad_value_threshold': -1000\n",
    "    },\n",
    "    'nuts': {\n",
    "        'type': 'output',\n",
    "        'data': dataset_creation.PreProcessBorderRaster(dataset_creation.ReadRasterFile(raster_nuts_fn), bad_value=-1),\n",
    "        'bad_value_threshold': -1\n",
    "    }\n",
    "}\n",
    "\n",
    "full_generator_sequence = dataset_creation.create_generator_sequence(rasters, window_size = window_size)\n",
    "sequence_separator = dataset_creation.SequenceSeparator(rasters, window_size = window_size)\n",
    "generator_sequences = sequence_separator(full_generator_sequence)\n",
    "generator_sequence = generator_sequences[0] + generator_sequences[1]\n",
    "\n",
    "log_regr = LogisticRegression(warm_start=True, random_state=0, verbose = 1, solver = 'saga', max_iter = 200, n_jobs = 4)\n",
    "\n",
    "train_dataset_generator = dataset_creation.InMemoryStridedArrayGeneratorForLogisticRegression(rasters, window_size = window_size, generator_sequence = generator_sequence, batch_size = training_size)\n",
    "for i in range(5):\n",
    "    X, y = next(train_dataset_generator)\n",
    "    log_regr.fit(X, y)\n",
    "    print(log_regr.score(X[y == 0], y[y == 0]))\n",
    "    print(log_regr.score(X[y == 1], y[y == 1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scripts.jobs.dataset_creation import ReadRasterFile, PreProcessBorderRaster, StoreCompositeDataHDF5, PreProcessPopulationRaster, PreprocessForResnet, PreProcessLogarithmPopulationRaster, PreProcessDEMRaster\n",
    "from matplotlib import pyplot\n",
    "\n",
    "raster_nuts_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/nuts_rst.tif'\n",
    "raster_dem_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/dem_aggr_rst.tif'\n",
    "raster_pop_fn = '/mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_rst.tif'\n",
    "\n",
    "pyplot.figure(figsize = (10,10))\n",
    "a = PreProcessBorderRaster(ReadRasterFile(raster_nuts_fn), bad_value = -1)\n",
    "pyplot.imshow(a, cmap='tab10')\n",
    "pyplot.show()\n",
    "\n",
    "pyplot.figure(figsize = (10,10))\n",
    "pyplot.imshow(PreprocessForResnet(PreProcessLogarithmPopulationRaster(PreProcessPopulationRaster(ReadRasterFile(raster_pop_fn)))), cmap='viridis')  # viridis\n",
    "pyplot.show()\n",
    "pyplot.figure(figsize = (10,10))\n",
    "a = PreprocessForResnet(PreProcessDEMRaster(ReadRasterFile(raster_dem_fn)))\n",
    "pyplot.imshow(a, cmap='viridis')\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = ReadRasterFile('/mnt/share/mnt/RESEARCH/SATELLITE/WORK/pop_rst.tif')\n",
    "a[a < -10] = -10\n",
    "a[(a < 3) & (a > -10)] = 0\n",
    "a[a > 2] = 1\n",
    "pyplot.hist(a, bins='auto') \n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}